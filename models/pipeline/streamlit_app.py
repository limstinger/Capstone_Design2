# streamlit_app.py
# -*- coding: utf-8 -*-
import os
import sys
import subprocess
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import joblib
from xgboost import XGBClassifier
from sklearn.metrics import (
    roc_auc_score, accuracy_score, f1_score,
    confusion_matrix, precision_recall_fscore_support
)
from scipy.stats import ks_2samp

# ==================== ê²½ë¡œ í•´ì„ ====================
def resolve_base_dir() -> Path:
    """
    Capstone_Design ë£¨íŠ¸ë¥¼ parents[2]ë¡œ ì¶”ì •.
    (â€¦/Capstone_Design/models/pipeline/streamlit_app.py ê¸°ì¤€)
    í´ë°±: parents[1] â†’ í˜„ì¬ ë””ë ‰í† ë¦¬
    """
    here = Path(__file__).resolve()
    cands = [
        here.parents[2],  # .../Capstone_Design
        here.parents[1],  # .../Capstone_Design/models
        here.parent,      # .../Capstone_Design/models/pipeline
    ]
    for b in cands:
        if (b / "data").exists() or (b / "models").exists():
            return b
    return here.parents[2]

BASE = resolve_base_dir()
PIPELINE_DIR = Path(__file__).resolve().parent

DATA_DIR = BASE / "data"
PROC_DIR = DATA_DIR / "processed"
PRED_DIR = DATA_DIR / "predictions"
MODELS_ROOT = BASE / "models"

PROC_DIR.mkdir(parents=True, exist_ok=True)
PRED_DIR.mkdir(parents=True, exist_ok=True)

DATA_CSV = PROC_DIR / "training_with_refined_features.csv"
PRED_CSV = PRED_DIR / "next_day_predictions.csv"

# ==================== ìœ í‹¸ í•¨ìˆ˜ ====================
def find_latest_final_dir(models_root: Path) -> Path:
    """
    models ë£¨íŠ¸ì—ì„œ ê°€ì¥ ìµœì‹ ì˜ final_* ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ëŠ”ë‹¤.
    """
    patterns = ["final_wavelet_transformer_*", "final_*"]
    cands = []
    for pat in patterns:
        cands += list(models_root.glob(pat))
    if not cands:
        for pat in patterns:
            cands += list(models_root.rglob(pat))
    cands = [p for p in cands if p.is_dir()]
    if not cands:
        raise FileNotFoundError("models í´ë”ì—ì„œ final_* ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì™„ë£Œí•˜ì„¸ìš”.")
    return max(cands, key=lambda p: p.stat().st_mtime)

@st.cache_resource
def load_meta_and_names(final_dir: Path):
    """
    ë©”íƒ€ ëª¨ë¸(XGB)ê³¼ í”¼ì²˜ ì´ë¦„, ì „ì²˜ë¦¬/ë³´ì • ë²ˆë“¤ì„ ë¡œë“œ.
    """
    pkl = final_dir / "preproc_and_calibrators.pkl"
    xgbp = final_dir / "meta_xgb.pkl"
    bundle = joblib.load(pkl)
    meta_model: XGBClassifier = joblib.load(xgbp)

    feat_names = bundle.get("meta_feature_names", None)
    if feat_names is None:
        feat_names = getattr(meta_model, "feature_names_in_", None)
        feat_names = list(feat_names) if feat_names is not None else [f"f{i}" for i in range(meta_model.n_features_in_)]

    return meta_model, feat_names, bundle

def fmt_date_for_metric(val) -> str:
    """
    st.metric ê°’ì€ str/int/float/Noneë§Œ í—ˆìš© â†’ ë‚ ì§œëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜.
    """
    try:
        if hasattr(val, "strftime"):
            return val.strftime("%Y-%m-%d")
        return str(val)
    except Exception:
        return str(val)

# ==================== Streamlit UI ====================
st.set_page_config(page_title="KOSPI Next-Day Forecast", layout="wide")
st.sidebar.title("âš™ï¸ ì„¤ì •")

st.sidebar.caption(f"BASE: `{BASE}`")
st.sidebar.caption(f"PIPELINE_DIR: `{PIPELINE_DIR}`")

use_recalib = st.sidebar.checkbox("ì˜ˆì¸¡ ì§í›„ ëˆ„ì  ë¼ë²¨ë¡œ ì¬ë³´ì •(--recalibrate)", value=False)
date_override = st.sidebar.text_input("ê¸°ì¤€ ë‚ ì§œ YYYY-MM-DD (ë¹ˆì¹¸=CSV ë§ˆì§€ë§‰ ë‚ ì§œ)", "")

colA, colB = st.sidebar.columns(2)
run_pred = colA.button("â–¶ ë‹¤ìŒ ì˜ì—…ì¼ ì˜ˆì¸¡ ì‹¤í–‰")
run_calib = colB.button("â™» ë³´ì •ê¸° ì¬í•™ìŠµ(+CSV ë°˜ì˜)")

# -------- ì˜ˆì¸¡ ì‹¤í–‰ ë²„íŠ¼ --------
if run_pred:
    # ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ ì´ë¦„: ì €ì¥ì†Œì— ë§ê²Œ ì‚¬ìš©
    script_name = "predict_next_day.py"
    if not (PIPELINE_DIR / script_name).exists():
        # predict_next_day.pyê°€ ì—†ìœ¼ë©´ predict_test.pyë¡œ í´ë°±
        alt = "predict_test.py"
        if (PIPELINE_DIR / alt).exists():
            script_name = alt
        else:
            st.error(f"ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {script_name} / {alt}")
            st.stop()

    cmd = [
        sys.executable,
        script_name,
        "--models-root", str(MODELS_ROOT),
        "--data-csv", str(DATA_CSV),
        "--pred-out", str(PRED_CSV),
    ]
    if date_override.strip():
        cmd += ["--date", date_override.strip()]
    if use_recalib:
        cmd += ["--recalibrate"]

    with st.spinner("ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘..."):
        proc = subprocess.run(cmd, cwd=str(PIPELINE_DIR), capture_output=True, text=True)
    st.code("\n".join(["> " + " ".join(cmd), proc.stdout, proc.stderr]))
    if proc.returncode == 0:
        st.success(f"ì˜ˆì¸¡ ì™„ë£Œ ë° CSV ì €ì¥! â†’ {PRED_CSV}")
    else:
        st.error("ì˜ˆì¸¡ ì‹¤í–‰ ì‹¤íŒ¨")

# -------- ë³´ì •ê¸° ì¬í•™ìŠµ ë²„íŠ¼ --------
if run_calib:
    calib_script = "calibrate_predictions.py"
    if not (PIPELINE_DIR / calib_script).exists():
        st.error(f"ë³´ì • ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {calib_script}")
        st.stop()

    cmd = [
        sys.executable, calib_script,
        "--pred-csv", str(PRED_CSV),
        "--calib-out", str(PRED_DIR / "post_calibrator.pkl"),
        "--min-n", "60",
        "--use-latest-only",
        "--write-back",
    ]
    with st.spinner("ë³´ì •ê¸° ì¬í•™ìŠµ ì¤‘..."):
        proc = subprocess.run(cmd, cwd=str(PIPELINE_DIR), capture_output=True, text=True)
    st.code("\n".join(["> " + " ".join(cmd), proc.stdout, proc.stderr]))
    if proc.returncode == 0:
        st.success("ë³´ì •ê¸° ì €ì¥ ë° CSV ê°±ì‹  ì™„ë£Œ!")
    else:
        st.error("ë³´ì •ê¸° ì¬í•™ìŠµ ì‹¤íŒ¨")

st.title("ğŸ“ˆ ë‹¤ìŒ ì˜ì—…ì¼ KOSPI ë“±ë½ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

# ==================== ë°ì´í„° ë¡œë“œ ====================
if not PRED_CSV.exists():
    st.info("ì•„ì§ ì˜ˆì¸¡ ê²°ê³¼ CSVê°€ ì—†ìŠµë‹ˆë‹¤. ì™¼ìª½ì—ì„œ 'ë‹¤ìŒ ì˜ì—…ì¼ ì˜ˆì¸¡ ì‹¤í–‰'ì„ ë¨¼ì € ëˆŒëŸ¬ ìƒì„±í•˜ì„¸ìš”.")
    st.stop()

df = pd.read_csv(PRED_CSV, parse_dates=["asof_date", "pred_for"], low_memory=False)
# run_noê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ë³´í˜¸
sort_cols = ["asof_date"] + (["run_no"] if "run_no" in df.columns else [])
df = df.sort_values(sort_cols, ascending=True).reset_index(drop=True)

# ìµœì‹  ì‹¤í–‰ í•œ ì¤„(ê° asof_dateì˜ ìµœì‹ )ë§Œ í•„í„°
if "is_latest" in df.columns:
    latest_mask = df["is_latest"].fillna(False).astype(bool)
    df_latest = df[latest_mask] if latest_mask.any() else df.groupby("asof_date", as_index=False).tail(1)
else:
    df_latest = df.groupby("asof_date", as_index=False).tail(1)

# ==================== ìƒë‹¨ KPI ====================
if not df_latest.empty:
    last = df_latest.iloc[-1]
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ê¸°ì¤€ ë‚ ì§œ(asof)", fmt_date_for_metric(last["asof_date"]))
    c2.metric("ì˜ˆì¸¡ ëŒ€ìƒ(pred_for)", fmt_date_for_metric(last["pred_for"]))
    c3.metric("ìµœì¢… í™•ë¥  proba_up", f"{float(last['proba_up']):.3f}" if pd.notna(last.get("proba_up", np.nan)) else "NaN")
    c4.metric("ì´ì§„ ì˜ˆì¸¡ pred_up", "â¬†ï¸ ìƒìŠ¹" if int(last.get("pred_up", 0)) == 1 else "â¬‡ï¸ í•˜ë½")

# ==================== ì‹œê³„ì—´ í”Œë¡¯ ====================
st.subheader("ìµœê·¼ ì˜ˆì¸¡ í™•ë¥ (ìµœì¢…)ê³¼ ë¼ë²¨(ìˆìœ¼ë©´)")
chart_df = df_latest[["asof_date", "proba_up"]].copy()
chart_df = chart_df.rename(columns={"asof_date": "date"})
if "label_up" in df_latest.columns:
    chart_df["label_up"] = df_latest["label_up"]
st.line_chart(data=chart_df.set_index("date"))

# ==================== ìš´ì˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ====================
st.subheader("ìš´ì˜ ì„±ëŠ¥ (ë¡¤ë§ AUC)")
if "label_up" in df_latest.columns:
    eval_df = df_latest.dropna(subset=["label_up"]).copy()

    def rolling_auc(s_proba, s_y, win=60):
        out = []
        for i in range(len(s_y)):
            L = max(0, i - win + 1)
            y = s_y.iloc[L:i+1]
            p = s_proba.iloc[L:i+1]
            if y.nunique() < 2:
                out.append(np.nan); continue
            out.append(roc_auc_score(y, p))
        return pd.Series(out, index=s_y.index)

    eval_df["AUC60"] = rolling_auc(eval_df["proba_up"], eval_df["label_up"], 60)
    eval_df["AUC20"] = rolling_auc(eval_df["proba_up"], eval_df["label_up"], 20)
    st.line_chart(eval_df.set_index("asof_date")[["AUC20", "AUC60"]])
else:
    st.info("ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ê°€ ì•„ì§ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# ==================== Threshold & ë¹„ìš© íƒìƒ‰ ====================
st.subheader("ì„ê³„ê°’ & ë¹„ìš© ë¯¼ê°ë„ íƒìƒ‰")
if "label_up" in df_latest.columns:
    thr = st.slider("Decision threshold", 0.1, 0.9, 0.5, 0.01)
    FP_cost = st.number_input("FP ë¹„ìš©", 0.0, 10.0, 1.0)
    FN_cost = st.number_input("FN ë¹„ìš©", 0.0, 10.0, 1.0)

    y = df_latest["label_up"].dropna()
    p = df_latest.loc[y.index, "proba_up"]
    yhat = (p >= thr).astype(int)
    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()
    prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average="binary")
    exp_cost = fp * FP_cost + fn * FN_cost

    st.write(f"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}")
    st.write(f"Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}, ê¸°ëŒ€ë¹„ìš©={exp_cost:.2f}")
else:
    st.info("ë¼ë²¨ì´ ìˆëŠ” êµ¬ê°„ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.")

# ==================== ì…ë ¥ ë¶„í¬ ë“œë¦¬í”„íŠ¸ ê°ì‹œ ====================
st.subheader("ì…ë ¥ ë¶„í¬ ë“œë¦¬í”„íŠ¸ ê°ì‹œ")
cand_cols = ["sentiment_z_30", "logret_USD_KRW_vol_5d", "vol_ratio_5_20"]
sel = [c for c in cand_cols if c in df.columns]
if sel:
    hist = df_latest.tail(126)  # ì•½ 6ê°œì›”
    recent = df_latest.tail(21) # ì•½ 1ê°œì›”
    rows = []
    for c in sel:
        a = hist[c].dropna(); b = recent[c].dropna()
        if len(a) > 30 and len(b) > 10:
            ks = ks_2samp(a, b).pvalue
            rows.append((c, ks))
    if rows:
        drift_df = pd.DataFrame(rows, columns=["feature", "ks_pvalue"]).sort_values("ks_pvalue")
        st.dataframe(drift_df, use_container_width=True)
        if (drift_df["ks_pvalue"] < 0.05).any():
            st.warning("ë¶„í¬ ë³€í™” ê°ì§€ë¨ (p<0.05). ì¬í•™ìŠµ ê¶Œê³ .")
else:
    st.caption("ë“œë¦¬í”„íŠ¸ ê°ì‹œí•  í”¼ì²˜ê°€ ì—†ìŒ")

# ==================== ê°„ë‹¨ ë°±í…ŒìŠ¤íŠ¸ ====================
st.subheader("ê°„ë‹¨ ë°±í…ŒìŠ¤íŠ¸ (í˜„ê¸ˆâ†”ì§€ìˆ˜, ë¹„ìš© 10bp)")
if "label_up" in df_latest.columns:
    cut = st.slider("ë°±í…ŒìŠ¤íŠ¸ cut-off", 0.3, 0.7, 0.5, 0.01)
    fee = 0.001
    base = df_latest.dropna(subset=["label_up"]).copy()
    signal = (base["proba_up"] >= cut).astype(int)
    # ì§€ìˆ˜ ìˆ˜ìµë¥  ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê°„ì´ ëŒ€ì²´: ë‹¤ìŒë‚  ë¼ë²¨ ê¸°ì¤€ Â±0.5%
    if "ret_kospi" not in base.columns:
        base["ret_kospi"] = np.where(base["label_up"] == 1, 0.005, -0.005)
    pos = signal.shift(1).fillna(0)  # ë‹¤ìŒë‚  ì§„ì…
    trade = pos.diff().abs().fillna(0)
    pnl = pos * base["ret_kospi"] - trade * fee
    eq = (1 + pnl).cumprod()
    st.line_chart(eq.reset_index(drop=True))

# ==================== ë©”íƒ€ XGB í”¼ì²˜ ì¤‘ìš”ë„ ====================
st.subheader("ë©”íƒ€ ëª¨ë¸(XGBoost) í”¼ì²˜ ì¤‘ìš”ë„ (gain ê¸°ì¤€)")
final_dir = None
try:
    final_dir = find_latest_final_dir(MODELS_ROOT)
    meta_model, feat_names, bundle = load_meta_and_names(final_dir)
    booster = meta_model.get_booster()
    score_map = booster.get_score(importance_type="gain")

    importances = []
    for i in range(meta_model.n_features_in_):
        key = f"f{i}"
        gain = score_map.get(key, 0.0)
        name = feat_names[i] if i < len(feat_names) else key
        importances.append((name, gain))
    imp_df = pd.DataFrame(importances, columns=["feature", "gain"]).sort_values("gain", ascending=False)
    st.dataframe(imp_df.head(30), use_container_width=True)
except Exception as e:
    st.warning(f"í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")

# ==================== ì„¤ëª…(ì´ë¯¸ì§€) í‘œì‹œ ====================
st.subheader("ì„¤ëª… ê²°ê³¼(ìˆìœ¼ë©´ ìë™ í‘œì‹œ)")
if final_dir is not None:
    img_cols = st.columns(3)
    cand_imgs = [
        ("ë©”íƒ€ SHAP summary", final_dir / "shap_meta_summary.png"),
        ("Transformer IG/SHAP", final_dir / "ig_low_summary.png"),
        ("CNN IG/SHAP", final_dir / "ig_high_summary.png"),
    ]
    for i, (title, p) in enumerate(cand_imgs):
        with img_cols[i % 3]:
            if p.exists():
                st.markdown(f"**{title}**")
                st.image(str(p))
            else:
                st.caption(f"{title}: ì´ë¯¸ì§€ ì—†ìŒ")
else:
    st.caption("ì„¤ëª… ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•  ëª¨ë¸ ë””ë ‰í„°ë¦¬ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

# ==================== íˆìŠ¤í† ë¦¬ í…Œì´ë¸” ====================
st.subheader("ì‹¤í–‰ íˆìŠ¤í† ë¦¬ (ìµœì‹  í”Œë˜ê·¸ ê¸°ì¤€)")
st.dataframe(df_latest.sort_values("asof_date"), use_container_width=True)

st.caption("â€» ì´ ì•±ì€ `streamlit run models/pipeline/streamlit_app.py` ë¡œ ì‹¤í–‰í•´ì•¼ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.")
