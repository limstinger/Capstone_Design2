#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
update_labels_in_predictions.py

- processed CSVì—ì„œ (asof_date == date) í–‰ì˜ label_upì„ ì°¾ì•„
  predictions CSVì˜ ë™ì¼ asof_date í–‰ë“¤ì— label_up / was_correctë¥¼ ì±„ì›€.
- ê°™ì€ asof_dateì— ì—¬ëŸ¬ runì´ ìˆìœ¼ë©´ ì „ë¶€ ê°±ì‹  (is_latestëŠ” ìœ ì§€).
- ì¶”ê°€:
  * used_sharpen / sharpen_T ê²°ì¸¡ì¹˜ ë³´ì •(ì—†ìœ¼ë©´ ìƒì„±, ë¬¸ìì—´/ë¶ˆë¦¬ì–¸ ì„ì—¬ë„ ìˆ«ìí™”)
  * ì»¬ëŸ¼ëª… ê³µë°± ì œê±°, asof_date ë¬¸ìì—´ ì •ê·œí™”(YYYY-MM-DD)
  * pred_up ì—†ê³  pred_proba_upë§Œ ìˆìœ¼ë©´ thresholdë¡œ 0/1 ìƒì„±
  * ì €ì¥ ì „ --backup ì˜µì…˜ ì œê³µ

Usage:
    python update_labels_in_predictions.py
    python update_labels_in_predictions.py --proc-csv data/processed/training_with_refined_features.csv \
                                           --pred-csv data/predictions/next_day_predictions.csv \
                                           --overwrite --threshold 0.5 --backup
"""
import argparse
from pathlib import Path
import shutil
import pandas as pd
import numpy as np


def _normalize_asof_date_series(s: pd.Series) -> pd.Series:
    """asof_dateê°€ datetime/ë¬¸ìì—´ í˜¼ì¬ì—¬ë„ YYYY-MM-DD ë¬¸ìì—´ë¡œ ì •ê·œí™”."""
    # ì´ë¯¸ ë¬¸ìì—´ì¸ ê°’ ë³´ì¡´ì„ ìœ„í•´ ì›ë³¸ ë³µì‚¬
    orig = s.astype(str)
    dt = pd.to_datetime(s, errors="coerce", utc=False)
    out = dt.dt.strftime("%Y-%m-%d")
    # ë³€í™˜ ì‹¤íŒ¨(NaT)ëŠ” ì›ë³¸ ë¬¸ìì—´ ìœ ì§€
    out = out.where(dt.notna(), orig.str.strip())
    # í˜¹ì‹œ 'YYYY-MM-DD HH:MM:SS' ê°™ì€ ê²½ìš° ìë¥´ê¸°
    out = out.str.slice(0, 10)
    return out


def _ensure_and_fill_sharpen_cols(pred: pd.DataFrame) -> pd.DataFrame:
    """
    used_sharpen/sharpen_T ì»¬ëŸ¼ì„ ë³´ì •/ìƒì„±í•˜ê³  ê²°ì¸¡ì„ ì±„ìš´ë‹¤.
    - used_sharpen: ì—†ìœ¼ë©´ 0, ë¬¸ìì—´/ë¶ˆë¦¬ì–¸ í˜¼ì¬ ì‹œ 1/0ìœ¼ë¡œ ì •ê·œí™” í›„ ê²°ì¸¡ 0
    - sharpen_T   : ì—†ìœ¼ë©´ 0.0, ìˆ«ì ë³€í™˜ ì‹¤íŒ¨/ê²°ì¸¡ 0.0
    """
    # ì—†ìœ¼ë©´ ìƒì„±
    if "used_sharpen" not in pred.columns:
        pred["used_sharpen"] = 0
    if "sharpen_T" not in pred.columns:
        pred["sharpen_T"] = 0.0

    # used_sharpen: ë¬¸ìì—´/ë¶ˆë¦¬ì–¸/ìˆ«ì í˜¼ì¬ â†’ 1/0 ì •ê·œí™”
    if pred["used_sharpen"].dtype == object:
        s = pred["used_sharpen"].astype(str).str.strip()
        mapping = {
            "True": 1, "true": 1, "1": 1, "yes": 1, "Y": 1, "y": 1, "t": 1, "T": 1,
            "False": 0, "false": 0, "0": 0, "no": 0, "N": 0, "n": 0, "f": 0, "F": 0,
            "": np.nan, "None": np.nan, "none": np.nan, "NaN": np.nan, "nan": np.nan
        }
        pred["used_sharpen"] = s.map(mapping)

    # ë¶ˆë¦¬ì–¸ â†’ int
    if pd.api.types.is_bool_dtype(pred["used_sharpen"]):
        pred["used_sharpen"] = pred["used_sharpen"].astype(int)
    else:
        # ê·¸ ì™¸ â†’ ìˆ«ìí™” í›„ ê²°ì¸¡ 0
        pred["used_sharpen"] = pd.to_numeric(pred["used_sharpen"], errors="coerce").fillna(0).astype(int)

    # sharpen_T: ìˆ«ìí™” í›„ ê²°ì¸¡ 0.0
    pred["sharpen_T"] = pd.to_numeric(pred["sharpen_T"], errors="coerce").fillna(0.0)

    return pred


def _ensure_pred_up(pred: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:
    """
    pred_upì´ ì—†ê³  pred_proba_upë§Œ ìˆì„ ë•Œ 0/1ë¡œ ìƒì„±.
    - threshold ì´ìƒì´ë©´ 1, ë¯¸ë§Œ 0.
    """
    if "pred_up" not in pred.columns and "pred_proba_up" in pred.columns:
        proba = pd.to_numeric(pred["pred_proba_up"], errors="coerce")
        pred["pred_up"] = (proba >= float(threshold)).astype("Int64").fillna(0).astype(int)
    return pred


def main():
    ap = argparse.ArgumentParser()
    base = Path(__file__).resolve().parents[2]
    ap.add_argument("--proc-csv", type=str, default=str(base / "data" / "processed" / "training_with_refined_features.csv"))
    ap.add_argument("--pred-csv", type=str, default=str(base / "data" / "predictions" / "next_day_predictions.csv"))
    ap.add_argument("--overwrite", action="store_true", help="ì˜ˆì¸¡ CSVì— ì´ë¯¸ ìˆëŠ” label_upë„ ë®ì–´ì”€")
    ap.add_argument("--threshold", type=float, default=0.5, help="pred_proba_up â†’ pred_up ë³€í™˜ ì„ê³„ê°’(ê¸°ë³¸ 0.5)")
    ap.add_argument("--backup", action="store_true", help="ì €ì¥ ì „ predictions CSV ë°±ì—…(.bak) ìƒì„±")
    args = ap.parse_args()

    proc_path = Path(args.proc_csv)
    pred_path = Path(args.pred_csv)

    if not proc_path.exists():
        raise FileNotFoundError(f"processed csv not found: {proc_path}")
    if not pred_path.exists():
        raise FileNotFoundError(f"predictions csv not found: {pred_path}")

    # ì½ê¸°
    proc = pd.read_csv(proc_path, parse_dates=["date"])
    pred = pd.read_csv(pred_path)

    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±° (ì—£ì§€ ì¼€ì´ìŠ¤ ë°©ì§€: 'used_sharpen ', ' sharpen_T' ë“±)
    proc.columns = proc.columns.str.strip()
    pred.columns = pred.columns.str.strip()

    # ê¸°ë³¸ ì»¬ëŸ¼ ì²´í¬
    if "label_up" not in proc.columns:
        raise RuntimeError("processed csvì— 'label_up' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if "asof_date" not in pred.columns:
        raise RuntimeError("predictions csvì— 'asof_date' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # processed: date â†’ ë¬¸ìì—´ asof_date í‚¤ ìƒì„±
    proc["asof_date"] = proc["date"].dt.strftime("%Y-%m-%d")
    key = proc[["asof_date", "label_up"]].dropna(subset=["asof_date"]).copy()

    # predictions: asof_date ì •ê·œí™”(ë¬¸ì/ë‚ ì§œ í˜¼ì¬ ëŒ€ì‘)
    pred["asof_date"] = _normalize_asof_date_series(pred["asof_date"])

    # ë¼ë²¨ ë³‘í•©
    pred = pred.merge(key, on="asof_date", how="left", suffixes=("", "_from_proc"))

    # ë®ì–´ì“°ê¸°/ë¹ˆê³³ë§Œ ì±„ìš°ê¸°
    if args.overwrite:
        pred["label_up"] = pred["label_up_from_proc"]
    else:
        pred["label_up"] = pred["label_up"].where(~pred["label_up"].isna(), pred["label_up_from_proc"])

    # ë³´ì¡° ì»¬ëŸ¼ ì œê±°
    if "label_up_from_proc" in pred.columns:
        pred.drop(columns=["label_up_from_proc"], inplace=True)

    # pred_up ë³´ì¥(ì—†ìœ¼ë©´ pred_proba_upìœ¼ë¡œ ìƒì„±)
    pred = _ensure_pred_up(pred, threshold=args.threshold)

    # was_correct ê°±ì‹  (pred_up & label_up ëª¨ë‘ ì¡´ì¬ ì‹œ)
    if {"pred_up", "label_up"}.issubset(pred.columns):
        mask = pred["label_up"].notna() & pred["pred_up"].notna()
        # ì•ˆì „í•œ ì •ìˆ˜ ë¹„êµ(ì†Œìˆ˜/ë¬¸ìì—´ ë“¤ì–´ì™€ë„ ìºìŠ¤íŒ…)
        pred.loc[mask, "was_correct"] = (
            pd.to_numeric(pred.loc[mask, "pred_up"], errors="coerce").round().astype("Int64")
            ==
            pd.to_numeric(pred.loc[mask, "label_up"], errors="coerce").round().astype("Int64")
        ).astype("Int64").fillna(0).astype(int)

    # ğŸ”§ used_sharpen / sharpen_T ê²°ì¸¡ ë³´ì •(ì—†ìœ¼ë©´ ìƒì„± + ì±„ì›€)
    pred = _ensure_and_fill_sharpen_cols(pred)

    # ì €ì¥ ì „ ë°±ì—…
    if args.backup:
        bak = pred_path.with_suffix(pred_path.suffix + ".bak")
        shutil.copy2(pred_path, bak)
        print(f"[OK] backup created â†’ {bak}")

    # ì €ì¥
    pred.to_csv(pred_path, index=False, encoding="utf-8-sig")

    # ë¡œê·¸
    labeled = int(pred["label_up"].notna().sum()) if "label_up" in pred.columns else 0
    sharpen_info = f"used_sharpen(dtype={pred['used_sharpen'].dtype}), sharpen_T(dtype={pred['sharpen_T'].dtype})"
    correct_ct = int(pred["was_correct"].notna().sum()) if "was_correct" in pred.columns else 0
    print(f"[OK] updated labels in {pred_path} (labeled rows: {labeled})")
    print(f"[OK] sharpen columns filled â†’ {sharpen_info}")
    print(f"[OK] was_correct updated rows: {correct_ct}")


if __name__ == "__main__":
    main()
